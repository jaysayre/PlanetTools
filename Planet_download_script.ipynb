{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "planet_download_script.py --- Last updated 12/24/21\n",
    "Contact: James Sayre, sayrejay@gmail.com\n",
    "\n",
    "Written to download images from the Planet API.\n",
    "\n",
    "Inputs:\n",
    "- Within the each subfolder \"STATECODE/MUNCODE/CYCLE_NAME_YEAR/\", looks for a shapefile called \"search_results_CYCLE_NAME_YEAR.shp\", which details each of the relevant satellite images for a given municipality and crop cycle.\n",
    "\n",
    "- \"data/muncodes/shp/MUNICIPIOS.shp\" -- INEGI provided shapefile of municipality shapes, municipality codes + names\n",
    "\n",
    "\n",
    "Outputs:\n",
    "Downloads of each PlanetScope asset, saved within \"STATECODE/Raw/ASSET_TYPE/\". For more information on asset types, see https://developers.planet.com/docs/data/psscene4band/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planet import api\n",
    "import os\n",
    "import json\n",
    "import requests as re\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from packaging import version\n",
    "from functools import partial\n",
    "import multiprocessing\n",
    "import wget\n",
    "import itertools\n",
    "\n",
    "### Directories\n",
    "base_dir = \"~/\"\n",
    "remote_sen_dir = os.path.join(base_dir, \"Remote Sensing\", \"Input/\")\n",
    "image_dir = os.path.join(base_dir, \"Remote Sensing\", \"Images/\")\n",
    "\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "intermediate_dir = os.path.join(base_dir, \"Intermediates\")\n",
    "\n",
    "### Inputs\n",
    "mun_shp =  os.path.join(data_dir, \"muncodes\",\"shp\",\"MUNICIPIOS.shp\") ### Region level shapefile\n",
    "search_region_satelite_imgs = os.path.join(intermediate_dir,\"search_regions_img_corr.csv\")\n",
    "\n",
    "### Params\n",
    "eng_or_esp = \"eng\" ###eng for english, else for spanish\n",
    "\n",
    "### Save your Planet API key a\n",
    "PLANET_API_KEY = os.environ['PL_API_KEY_James']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Programs\n",
    "def return_date_id(image_id):\n",
    "    parts = image_id.split('_')[0]\n",
    "    year,month, day = parts[:4], parts[4:6], parts[6:]\n",
    "    if eng_or_esp == \"eng\":\n",
    "        return str(month)+'/'+str(day)+'/'+str(year)\n",
    "    else:\n",
    "        return str(day)+'/'+str(month)+'/'+str(year)\n",
    "\n",
    "def re_get_check(url, api_key=PLANET_API_KEY):\n",
    "    ### Written to ignore connection snags\n",
    "    has_connected = False\n",
    "    while has_connected == False:\n",
    "        result = re.get(url, auth=HTTPBasicAuth(api_key, ''))\n",
    "#         print(result.status_code)\n",
    "        if result.status_code != 404 and result.status_code != 429:\n",
    "            has_connected = True\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(5)\n",
    "    return result\n",
    "    \n",
    "def check_id_assets(image_id, item_type=\"PSScene4Band\"):\n",
    "    id_url = 'https://api.planet.com/data/v1/item-types/{}/items/{}/assets'.format(item_type, image_id)\n",
    "    # Returns JSON metadata for assets in this ID.\n",
    "    try:\n",
    "        asset = re_get_check(id_url)\n",
    "        # List of asset types available for this particular satellite image\n",
    "        return list(asset.json().keys())\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def return_image_file_path(chosen_mun,ciclo,image_id,asset_type='analytic_sr',\n",
    "                          create_path=True):\n",
    "    state_code = str(int(chosen_mun)).replace(str(int(chosen_mun))[-3:],\"\")+\"/\"+ciclo+\"/\"\n",
    "\n",
    "    fl_dr = image_dir+state_code+asset_type+\"/\"\n",
    "    if create_path:\n",
    "        if not os.path.exists(fl_dr):\n",
    "            os.makedirs(fl_dr)\n",
    "    \n",
    "    if asset_type == \"analytic_sr\":\n",
    "        asset_abbrev = \"_sr\"\n",
    "        output_fl = fl_dr+image_id+asset_abbrev+\".tif\"\n",
    "    elif asset_type == \"analytic\":\n",
    "        asset_abbrev = \"_a\"\n",
    "        output_fl = fl_dr+image_id+asset_abbrev+\".tif\"\n",
    "    elif asset_type == \"analytic_xml\":\n",
    "        output_fl = fl_dr+image_id+\".xml\"\n",
    "    else:\n",
    "        asset_abbrev = \"_\"+asset_type\n",
    "        output_fl = fl_dr+image_id+asset_abbrev+\".tif\"\n",
    "    return output_fl\n",
    "\n",
    "def activate_image_id(image_id,chosen_mun, ciclo, item_type=\"PSScene4Band\", asset_type='analytic_sr'):\n",
    "    id_url = 'https://api.planet.com/data/v1/item-types/{}/items/{}/assets'.format(item_type, image_id)\n",
    "    output_fl = return_image_file_path(chosen_mun,ciclo,image_id,asset_type)\n",
    "\n",
    "    if not os.path.isfile(output_fl):\n",
    "        try:\n",
    "            # Returns JSON metadata for assets in this ID.\n",
    "            asset = re_get_check(id_url)\n",
    "\n",
    "            if asset != None:\n",
    "                print(asset.status_code)\n",
    "                # List of asset types available for this particular satellite image\n",
    "                status = asset.json()[asset_type]['status']\n",
    "                self_link = asset.json()[asset_type][\"_links\"][\"_self\"]\n",
    "                activation_link = asset.json()[asset_type][\"_links\"][\"activate\"]\n",
    "\n",
    "                if status != \"active\":\n",
    "                    # Request activation of the 'analytic' asset:\n",
    "                    activate_result = re_get_check(activation_link)\n",
    "        except:\n",
    "            print(\"Couldn't activate image id:\", image_id)\n",
    "            \n",
    "def download_image_id(image_id,chosen_mun, ciclo, item_type=\"PSScene4Band\", asset_type='analytic_sr'):\n",
    "    id_url = 'https://api.planet.com/data/v1/item-types/{}/items/{}/assets'.format(item_type, image_id)\n",
    "    output_fl = return_image_file_path(chosen_mun,ciclo,image_id,asset_type,create_path=True)\n",
    "\n",
    "    if not os.path.isfile(output_fl):\n",
    "        # Returns JSON metadata for assets in this ID.\n",
    "        asset = re_get_check(id_url, PLANET_API_KEY)\n",
    "\n",
    "        # List of asset types available for this particular satellite image\n",
    "        if asset != None:\n",
    "            status = asset.json()[asset_type]['status']\n",
    "            self_link = asset.json()[asset_type][\"_links\"][\"_self\"]\n",
    "            activation_link = asset.json()[asset_type][\"_links\"][\"activate\"]\n",
    "\n",
    "            if status != \"active\":\n",
    "                return False\n",
    "            else:\n",
    "                activation_status_result = re_get_check(self_link, PLANET_API_KEY)\n",
    "                wget.download(activation_status_result.json()[\"location\"],output_fl)\n",
    "                if os.path.isfile(output_fl):\n",
    "                    if os.stat(output_fl).st_size < 120:\n",
    "                        os.remove(output_fl)\n",
    "                        return False\n",
    "                    else:\n",
    "                        print(\"Downloaded file successfully at \", output_fl)\n",
    "                        return True\n",
    "        else:\n",
    "            print(\"Couldn't download:\", image_id)\n",
    "            return False\n",
    "    else:\n",
    "        print(\"Already downloaded \"+asset_type+\" asset\")\n",
    "        return True\n",
    "\n",
    "def download_all_in_list(to_download_list,activate=True,queue_ahead=50):\n",
    "    undownloaded_parts = []\n",
    "    for i, download_part in enumerate(to_download_list):\n",
    "        ### Start by activating future images to download \n",
    "        if activate:\n",
    "            if i == 0:\n",
    "                for j in range(queue_ahead):\n",
    "                    if j < len(to_download_list):\n",
    "                        next_img_id, next_cic, next_mun = to_download_list[j]\n",
    "                        next_img_fl = return_image_file_path(next_mun,next_cic,next_img_id)\n",
    "                        if not os.path.isfile(next_img_fl):\n",
    "                            print(\"Now activating asset: \", j)\n",
    "                            print(next_img_id)\n",
    "                            asset_types = check_id_assets(next_img_id)\n",
    "                            if 'analytic_sr' in asset_types:\n",
    "                                activate_image_id(next_img_id, chosen_mun = next_mun,  ciclo=next_cic,asset_type='analytic_sr') ### This activates the SR image\n",
    "                            if 'udm2' in asset_types:\n",
    "                                activate_image_id(next_img_id, chosen_mun = next_mun, ciclo=next_cic, asset_type='udm2') ### This activates the v2 cloud map\n",
    "                            elif 'udm' in asset_types:\n",
    "                                activate_image_id(next_img_id, chosen_mun = next_mun, ciclo=next_cic, asset_type='udm') ### This activates the cloud map\n",
    "                            elif 'analytic_xml' in asset_types:\n",
    "                                activate_image_id(next_img_id, chosen_mun = next_mun, ciclo=next_cic, asset_type='analytic_xml') ### This activates the xml file\n",
    "            if i+queue_ahead < len(to_download_list):\n",
    "                next_img_id, next_cic, next_mun = to_download_list[i+queue_ahead]\n",
    "                next_img_fl = return_image_file_path(next_mun,next_cic,next_img_id)\n",
    "                if not os.path.isfile(next_img_fl):\n",
    "                    print(\"Now activating asset: \", i+queue_ahead)\n",
    "                    asset_types = check_id_assets(next_img_id)\n",
    "                    if 'analytic_sr' in asset_types:\n",
    "                        activate_image_id(next_img_id, chosen_mun = next_mun,  ciclo=next_cic,asset_type='analytic_sr') ### This activates the SR image\n",
    "                    if 'udm2' in asset_types:\n",
    "                        activate_image_id(next_img_id, chosen_mun = next_mun, ciclo=next_cic, asset_type='udm2') ### This activates the v2 cloud map\n",
    "                    elif 'udm' in asset_types:\n",
    "                        activate_image_id(next_img_id, chosen_mun = next_mun, ciclo=next_cic, asset_type='udm') ### This activates the cloud map\n",
    "                    elif 'analytic_xml' in asset_types:\n",
    "                        activate_image_id(next_img_id, chosen_mun = next_mun, ciclo=next_cic, asset_type='analytic_xml') ### This activates the xml file\n",
    "        \n",
    "        ### Now download this image \n",
    "        image_id, ciclo, muncode = download_part\n",
    "        image_fl = return_image_file_path(muncode,ciclo,image_id)\n",
    "        if not os.path.isfile(image_fl):\n",
    "            print(\"Now downloading asset: \", i)\n",
    "            asset_types = check_id_assets(image_id)\n",
    "            if 'analytic_sr' in asset_types:\n",
    "                dl_status = download_image_id(image_id, chosen_mun = muncode, ciclo = ciclo, asset_type='analytic_sr') ### This downloads the SR image\n",
    "                if dl_status == False:\n",
    "                    undownloaded_parts.append(download_part)\n",
    "                if 'udm2' in asset_types:\n",
    "                    dl_status_udm2 = download_image_id(image_id, chosen_mun = muncode, ciclo = ciclo, asset_type='udm2') ### This downloads the v2 cloud map\n",
    "                    if dl_status_udm2 == False:\n",
    "                        undownloaded_parts.append(download_part)\n",
    "                elif 'udm' in asset_types:\n",
    "                    dl_status_udm = download_image_id(image_id, chosen_mun = muncode, ciclo = ciclo, asset_type='udm') ### This downloads the cloud map\n",
    "                    if dl_status_udm == False:\n",
    "                        undownloaded_parts.append(download_part)\n",
    "                elif 'analytic_xml' in asset_types:\n",
    "                    dl_status_xml = download_image_id(image_id, chosen_mun = muncode, ciclo = ciclo, asset_type='analytic_xml') ### This downloads the xml file                                            \n",
    "                    if dl_status_xml == False:\n",
    "                        undownloaded_parts.append(download_part)\n",
    "    return undownloaded_parts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in shapefile for country extent\n",
    "df = gpd.read_file(mun_shp)\n",
    "### We need to reproject this shapefile into lat/lon coordinates, or another projection potentially\n",
    "df = df.to_crs(epsg=4326)\n",
    "df['muncode'] = df['CVE_ENT']+df['CVE_MUN']\n",
    "df['muncode'] = df['muncode'].astype(int)\n",
    "\n",
    "df['area'] = df.geometry.area \n",
    "df.sort_values('muncode', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_muns =  [2001, 2002, 2003, 2004, 2005] ### Baja California\n",
    "bid_images = ''\n",
    "search_df = gpd.GeoDataFrame()\n",
    "mun_selected_df = df[df['muncode'].isin(target_muns)]\n",
    "img_fls_dled = []\n",
    "for muncode in target_muns:\n",
    "    state_code = str(muncode).replace(str(muncode)[-3:],\"\")+\"/\"\n",
    "    ciclos = ['summer_', 'winter_', 'spring_']\n",
    "\n",
    "    fl_dr = image_dir+state_code\n",
    "    if os.path.exists(fl_dr):\n",
    "        for r,d,f in os.walk(fl_dr):\n",
    "            for file in f:\n",
    "                if '_sr.tif' in file:\n",
    "                    if file.split('_sr.tif')[0] not in img_fls_dled:\n",
    "                        img_fls_dled.append(file.split('_sr.tif')[0])\n",
    "\n",
    "    for yr in range(16,22):\n",
    "        for ciclo in ciclos:\n",
    "            yr = str(yr)\n",
    "            input_fl_dir_srt = remote_sen_dir+state_code+str(muncode)+\"/\"+ciclo+'start_'+yr+\"/\"\n",
    "            input_fl_dir_end = remote_sen_dir+state_code+str(muncode)+\"/\"+ciclo+'end_'+yr+\"/\"\n",
    "\n",
    "            search_df_srt_fl = input_fl_dir_srt+'search_results_'+ciclo+'start_'+yr+'.shp'\n",
    "            search_df_end_fl = input_fl_dir_end+'search_results_'+ciclo+'end_'+yr+'.shp'\n",
    "            if os.path.isfile(search_df_srt_fl):\n",
    "                if os.path.isfile(search_df_end_fl):\n",
    "                    search_df_srt = gpd.read_file(search_df_srt_fl)\n",
    "                    search_df_srt['time'] = ciclo+\"start_\"+yr\n",
    "                    search_df_end = gpd.read_file(search_df_end_fl,SHAPE_RESTORE_SHX='YES')\n",
    "                    search_df_end['time'] = ciclo+\"end_\"+yr\n",
    "\n",
    "                    if os.path.isfile(input_fl_dir_srt+'mun_boxes_'+ciclo+'start_'+yr+'.csv'):\n",
    "                        box_df_srt = pd.read_csv(input_fl_dir_srt+'mun_boxes_'+ciclo+'start_'+yr+'.csv')\n",
    "                    if os.path.isfile(input_fl_dir_end+'mun_boxes_'+ciclo+'end_'+yr+'.csv'):\n",
    "                        box_df_end = pd.read_csv(input_fl_dir_end+'mun_boxes_'+ciclo+'end_'+yr+'.csv')\n",
    "\n",
    "                    search_df = search_df.append(search_df_srt).reset_index(drop=True)\n",
    "                    search_df = search_df.append(search_df_end).reset_index(drop=True)\n",
    "\n",
    "search_df['date']=search_df['id'].apply(return_date_id)\n",
    "search_df['year'] = search_df['time'].apply(lambda x: str(x).split('_')[-1])\n",
    "search_df['cic'] = search_df['time'].apply(lambda x: str(x).split('_')[0])\n",
    "search_df['uid'] = 'MUN'+search_df['muncode'].astype(str)+\"_YEAR\"+search_df['year']+\"_CIC\"+search_df['cic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For areas with multiple epsg codes in one muncode-cycle, only download images from \"largest\" epsg\n",
    "### If area has only one epsg, this also selects the only epsg\n",
    "epsg_df = search_df.groupby(['uid','epsg']).size().reset_index()\n",
    "print(len(epsg_df))\n",
    "epsg_df.columns = ['uid','epsg','num_epsg']\n",
    "count_df = search_df.groupby('uid').size().reset_index()\n",
    "\n",
    "count_df.columns = ['uid','cicyr_tot']\n",
    "epsg_df = epsg_df.merge(count_df,on='uid',how='left')\n",
    "epsg_df['share'] = epsg_df['num_epsg']/epsg_df['cicyr_tot']\n",
    "### Keep EPSG with largest share of EPSG codes\n",
    "max_epsg_df = epsg_df.groupby('uid')['share'].max().reset_index()\n",
    "max_epsg_df.columns = ['uid','max_share']\n",
    "epsg_df = epsg_df.merge(max_epsg_df,on='uid',how='left')\n",
    "epsg_df = epsg_df[epsg_df['share'] >= epsg_df['max_share']]\n",
    "search_df = search_df.merge(epsg_df,on=['uid','epsg'],how='inner')\n",
    "search_df.drop('uid',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset down to images that we don't already have\n",
    "already_dl_df = search_df[search_df['id'].isin(img_fls_dled)]\n",
    "download_df = search_df[~search_df['id'].isin(img_fls_dled)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important: WE HAVE TO ENSURE THAT ALL IMAGES HAVE THE SAME CRS (geographic projection)\n",
    "## This part here is designed to ensure we don't download images with different CRSes\n",
    "## What if we do -- go back to planet_api_querying and force imagery to be downloaded from one CRS\n",
    "## How? Modify return_relevant_shapes fxn with the return_epsg arg set to the CRS we want\n",
    "## To requery imagery for a crop cycle, just delete the saved shapefile listing the relevant satellite images\n",
    "if len(download_df['epsg'].unique()) > 1:\n",
    "    raise NOTTHESAMEEPSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plot available imagery selected for each season\n",
    "for yr in range(16,22):\n",
    "    for ciclo in ciclos:\n",
    "        for start_end in ['start','end']:\n",
    "            seasons = [ciclo+start_end+'_'+str(yr)]\n",
    "            ciclo_download_df = search_df[search_df['time'].isin(seasons)]\n",
    "            ### Optional: subset down toonly image ids that cover box id of interest\n",
    "#             ciclo_download_df = ciclo_download_df[ciclo_download_df['id'].isin(bid_images)]\n",
    "            ciclo_already_dl_df = ciclo_download_df[ciclo_download_df['id'].isin(img_fls_dled)]\n",
    "            ciclo_to_download_df = ciclo_download_df[~ciclo_download_df['id'].isin(img_fls_dled)]\n",
    "            ciclo_badcov_df = ciclo_to_download_df[ciclo_to_download_df['cloud_cov'] > 0.30] #needs to scale with size\n",
    "            ciclo_goodcov_df = ciclo_to_download_df[ciclo_to_download_df['indep_cvrg'] >= 0.0000001] # needs to scale with size\n",
    "            if len(ciclo_download_df) > 0:\n",
    "                ### If you want to plot the outline of the municipality against the chosen imagery outlines\n",
    "                fig, ax = plt.subplots(figsize=(7, 7))\n",
    "                mun_selected_df.plot(ax=ax,color='white', edgecolor='black', alpha=0.7)\n",
    "                ### Blue are images we already have\n",
    "                ciclo_already_dl_df.plot(ax=ax,color='Blue', edgecolor='white',alpha=0.4)\n",
    "                ### Red are images we are chosing not to download based on poor cloud coverage coverage\n",
    "                ciclo_badcov_df.plot(ax=ax,color='Red', edgecolor='white',alpha=0.4)\n",
    "                ### Green are images we will download\n",
    "                ciclo_goodcov_df.plot(ax=ax,color='green', edgecolor='white',alpha=0.4)\n",
    "\n",
    "                plt.title(ciclo+str(yr)+'_'+start_end)\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset down to images whose independent coverage (i.e. whose coverage of the municipality is independent \n",
    "### of the coverage of the other queried images is greater than some threshold).\n",
    "### The tradeoff is that occasionally we'll miss being able to look at areas on the borders, but at a great payoff\n",
    "### in terms of necessary image reduction.\n",
    "download_df = download_df[download_df['indep_cvrg'] >= 0.0000001] \n",
    "download_df = download_df[download_df['cloud_cov'] <= 0.3]\n",
    "### To download images in order of importance/coverage\n",
    "download_df = download_df.sort_values('indep_cvrg',ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_download = []\n",
    "for i in download_df.index:\n",
    "    image_id = download_df.loc[i,'id']\n",
    "    ciclo = download_df.loc[i,'time']\n",
    "    mc = download_df.loc[i,'muncode']\n",
    "    to_download.append((image_id,ciclo,int(mc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr = multiprocessing.Manager()\n",
    "pool_size = multiprocessing.cpu_count()\n",
    "split_ids = np.array_split(to_download, pool_size)\n",
    "pool = multiprocessing.Pool(processes=pool_size)\n",
    "download_these=partial(download_all_in_list, activate=True)\n",
    "undled_images = zip(*pool.map(download_these, split_ids))\n",
    "undled_images = list(itertools.chain(*undled_images))\n",
    "undled_split_ids = np.array_split(undled_images, pool_size)\n",
    "undled_images_v2 = zip(*pool.map(download_these, undled_split_ids))\n",
    "undled_images_v2 = list(itertools.chain(*undled_images_v2))\n",
    "undled_split_ids_v2 = np.array_split(undled_images_v2, pool_size)\n",
    "undled_images_v3 = zip(*pool.map(download_these, undled_split_ids_v2))\n",
    "undled_images_v3 = list(itertools.chain(*undled_images_v3))\n",
    "pool.close()\n",
    "print(\"Number of undownloaded images:\", len(undled_images_v3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
